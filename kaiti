摘要
    基于时间序列的预测可以丰富智能运维领域异常检测的手段。为了应对实际IT运维指标数据时间粒度多样、多为非线性且数据常有缺失等挑战，通过改进和优化现有趋势预测算法模型，能够更好地满足IT运维系统的实际需求、提高预测精度、减少异常检测阶段的错误告警信息，从而降低运维人员的无效工作量。
	课题以某券商数据中心的智能运维平台的异常检测方案设计为背景，利用python语言，结合国内外学者研究成果，设计并实现趋势预测算法模型，通过对数据集的仿真模拟实验，分析并评估预测结果，使之可以应用于智能运维领域。在此基础上，将算法模型应用于其他时间序列预测中，验证模型的泛化能力。报告包括对课题有关的研究背景、研究目标和内容以及主要研究方案和技术路线进行了介绍，最后给出了进度安排。
 5.1 课题背景
5.1.1 研究背景
随着计算机软硬件技术、网络信息技术的快速发展，IT系统规模不断扩大、日益复杂化，其服务范围涵盖了人类社会生产和生活的方方面面，涉及公共服务、网络金融、商务交易、工业生产等各行各业。根据中国互联网络信息中心(CNNIC)于2019年8月发布的《第44次中国互联网络发展状况统计报告》，截至2019年6月，我国已拥有网站数量518万个，IPv4地址数量达3.8亿个，IPv6地址数量跃居全球第一。互联网基础资源日益庞大，为保证IT系统可靠、安全、稳定地运行和提供服务，以及避免系统高危停机等问题带来的经济损失和用户流失，IT运维在IT服务管理中扮演着越来越重要的角色。
IT运维(IT Operations)，指为提高IT系统运营水平和服务水平，对IT系统的网络、软硬件等方面实施管理和维护的一系列行为和方式，是IT服务管理的重点。IT运维日趋成熟，经历了从手工运维、脚本工具运维到自动化运维的发展过程，其工作模式逐渐从被动响应、纯手工、凭借经验、依靠体力转变为主动发现、基于平台、累积知识和自动化操作，然而，自动化运维实际上只是一个基于人为指定规则的专家系统习。随着IT系统业务规模不断扩张、系统形态持续变迁，大量复杂的领域知识和场景规则无法得到有效及时的更新。同时，IT基础设施和应用所产生的数据量和种类迅速增长，得不到高效的管理和利用，在发现和解决系统问题等方面也存在大量延迟。2018年，Gartner咨询公司在对全球3000多名首席信息官(CIO)的采访中发现，现代企业正面临大规模的数字化转型。在竞争日趋激烈的市场环境中，自动化运维已无法满足企业数字化转型的需求。随着人工智能(Artificial Intelligence，AI)的浪潮不断推进，越来越多的企业将其引入并运用于IT运维领域，以弥补自动化运维的不足。
为满足企业日益增长的数字化、智能化转型的需求，高效率、低成本的AIOps应运而生。2017年，Gaitner咨询公司首次提出了AIOps(Artificial Intelligence for IT Operations)的概念，中文释义为“智能运维”智能运维，基于自动化运维平台，利用人工智能技术，将大数据和机器学习方法融合，主动学习和更新运维场景知识，为解决运维问题提供决策支持。
近几年，智能运维受到国内外业界的高度关注，相关研究和实践取得一定成果且持续发展。关于智能运维的讨论和分享爆发式地出现在各相关行业会议和网络媒体上，这其中包括全球运维大会GOPS、互联网应用运维实践大会GNUTCon、全球敏捷运维峰会Gdevops、全球软件与运维峰会WOT，以及CSDN技术博客等。来自互联网(如微软、百度、阿里)、金融(如交通银行、上海证券交易所)等领域的专家和来自各大高校的学者(如清华大学Netman研究组)纷纷走向前台主动分享和交流。2018年，国内AIOps标准工作组(成员包括来自BATJ、华为、中国银行等企业的领域专家)、IT运维委员会及高效运维社区联合发起制定了《企业级AIOps实施建议》白皮书,2019年，Gartner咨询公司发布了最新的AIOps平台市场指南，并预计到2022年40%(原为5%)的IT运维将结合大数据和机器学习技术。
   IT运维走向智能运维是企业业务和相关技术高速发展的必然结果，智能运维对IT运维的影像也具有长期性和变革性。伴随着企业升级转型、人工智能 日趋成熟，智能运维AIOps时代已经到来。
5.1.2 研究动机
智能运维AIOps的关键场景和技术如图1-1所示，针对IT系统中的历史事件、当前事件和未来事件进行分类。运行故障在IT系统中是不可避免的，为保证系统的健壮性、可靠性和可访问性，快速检测故障至关重要，时间序列预测算法基于历史数据对未来可能发生的事件做出预测，提前预警，是异常检测中的重要一环，因此，本文结合智能运维异常检测背景，主要研究时间序列预测技术。从而满足现代企业数字化、智能化运维场景的需求，同时也促进AIOps的进一步发展与完善。
时间序列预测旨在预测系统运行过程中可能会发生的异常行为。运维平台在对IT系统实时监测之前，会预先定义一些指标，在系统运行过程中平台会根据这些指标采集每个系统组件的监测数据，每个指标对应一条时间序列。当时序数据观测值明显偏离预测值时，如发生突升、突降、抖动等现象。通常说明了对应的组件可能发生了某种故障，例如路由器中断、服务调用延迟等，趋势预测主要通过分析特定指标的时间序列曲线从而发现上述现象。通常，关于时间序列的异常标签、先验知识很难获取；不断更新的系统又对算法的实时性要求高；时间序列的异常表现形式也多种多样。算法研究的根本目的是更多地、更准确的捕获时间序列中的异常，减少重复错误的告警。
5.1.3研究意义
AIOps实际上是一个跨学科的新兴领域，为实现AIOps愿景，业界还有很长的路要走，本文专注于AIOps中的算法研究。
异常检测算法的研究对AIOps的推进和落地具有重要意义，趋势预测算法作为异常检测中的关键场景和技术，能够完善和丰富AIOps的智能算法策略库；算法旨在主动发现运维问题，能够让运维人员告别人脑决策和手工操作等方式，从大量繁琐、复杂、耗时、易出错的运维工作中解放出来；最终，帮助实现运维模式和人员身份的逐步转型，推动AIOps的进一步发展与完善。
AIOps的推进有助于推动相关技术的学术研究与发展。AIOps关键场景和技术的研究，结合日渐成熟的人工智能等技术，能够进一步拓展和加深学术界在相关技术和方法上的探索，从而帮助构建更完善的智能运维体系，形成整个领域的良性循环和稳步提升。AIOps的推进最终帮助企业实现数字化、智能化转型。AIOps以创造商业价值为导向，能够帮助企业提升IT系统服务质量和客户满意度，提高IT工程效率，降低企业运营成本，实现业务的持续健康增长，最终帮助企业推进数字化、智能化转型的进程除互联网、金融外，AIOps在医疗、化工、航空航天、物联网等领域都将有很好的应用。

5.2 文献综述
5.2.1 智能运维综述
如今的互联网运营格局比以往任何时候都更加复杂。随着网络基础架构的发展，It系统从静态可预测的物理系统过渡为可动态更新和配置的软硬件资源的总和，云计算技术的高速发展使得系统服务的规模和复杂性不断增加。传统的运维工具和模式已无法管理动态变化的系统环境，动态的技术和流程成为高效运维管理的迫切需求8。同时，为实现对系统的实时监测，需要关联跨多个领域的数百万个数据点并进行分析和可视化，这要求大数据和人工智能等技术的引入。
2013年，全球最具权威的IT研究与顾问咨询公司Gartner提出了ITOA (IT Operations Analytics)的概念，即IT运维分析，集中于以数据为中心的监视和分析。2016 年，Gartner 将ITOA概念升级为AIOps (Algorithmic IT Operations)，即基于算法的IT运维，主张通过引入机器学习等算法，集成多个数据源，促进IT运维模式向主动化、个性化和动态化方向发展。2017年, Garther 将AIOps的全称修改为Atificial Itelligence for IT Operations,即智能运维，反映了人工智能技术的广泛应用以及业界对相关技术的兴趣和投资的增长。2019 年，Gartner 发布了最新的AIOps平台市场指南，预计到2022年40% (原为5%)的IT运维将结合大数据和机器学习技术。
AIOps是IT运维分析和管理(ITOA/TTOM) 体系与人工智能等技术相结合的产物，智能运维时代已经到来。


5.2.2 异常检测相关概念
异常检测（Anomaly Detection）在多种科研和应用领域都是一个非常重要的课题。异常检测指的是从数据中找到不符合预期的“行为模式”。这些不符合预期的行为模式也经常被叫做anomalies、outliers等。异常检测已经在各个领域得到了广泛的应用，如信用卡欺诈检测、保险或医疗保健、网络安全入侵检测、安全关键系统中的故障检测以及敌方活动的军事监视。
异常检测的重要性主要在于数据中的异常信息可以转化为更为重要的关键信息。例如信用卡交易中的异常信息可以推断出异常的信用卡，甚至是盗窃者的身份信息[Aleskerov et al. 1997]。
发现数据中的异常点或离群点的问题早在19世纪就被统计学界研究了[Edgeworth 1887]。随着时间的推移，各种各样的异常检测技术在多个研究团体中被提出。其中许多技术是专门为某些应用领域开发的，而其它的技术则更为通用化。
分析生产环境中的数据，常见的指标数据可以分为周期型、稳定型和不稳定型三种13，如下图所示：
 
图3.1 周期型指标
 
图3.2 稳定型指标
 
图3.3 不稳定型指标
在前人的研究成果中，针对周期型指标的异常检测，有基于时间序列分解（Time Series Decomposition）的算法，以及基于Holt-Winters算法等等。针对稳定性指标的异常检测，主要有静态阈值算法，移动平均、带权重的移动平均以及指数移动平均，还有经典的ARIMA算法。针对不稳定型指标的异常检测，主要有基于极值理论（Extreme Value Theory）和小波变换（Wavelet）的算法。另外，还有一些研究针对的是异常数据量太小的问题，提出了异常注入算法。
近年来，国内外学术界提出了许多时间序列异常检测方法，这些方法被广泛应用于各个领域，例如公共云平台[9、环境传感器J10]、 网络服务1-1等。目前存在一些基于监督学习( supervised)的异常检测方法。例如，Liu等(2015)提出了一种基于随机森林分类器的自动异常检测方法[4]。Timcenko 等(2017)利用机器学习中的集成分类器对网络入侵现象进行检测，并对包括AdaBoost、LogitBoost和GentleBoost 在内的集成算法进行对比研究(15]。基于监督学习的异常检测方法需要使用带标签的样本数据(正常数据和异常数据)来训练模型并进行类别预测。通常，这些标签很难获取，大部分需要定期手动标记，即使能够获取其准确性也难以保证，样本的类别分布也极其不均衡[16]。因此，异常检测问题通常采用无监督(unsupervised)的方式，隐含地假设数据集中仅存在极少量的异常。目前，无监督异常检测方法大多基于统计分析技术。
5.2.3 时间序列趋势预测综述
在智能运维领域，时间序列预测是异常检测的重要手段和方法。
时间序列预测的目标是根据当前和过去的数据样本来估计某些将来的值，主要分为线性和非线性两种估计器。在过去几十年中，已有大量有关线性预测的文献。现实世界中的时间序列预测应用程序通常不属于线性预测的范畴，相反，它们通常以非线性模型为特征。时间序列预测技术已在许多实际应用中使用，例如金融市场预测，电力负荷预测，天气和环境状态预测以及其他一些可靠性预测应用场景。对于这些应用而言，底层的系统模型和时间序列数据生成过程通常很复杂，并且这些系统的模型通常也不是先验预设好的。对于这些系统产生的时间序列数据，有时无法使用常见的线性方法来实现其预测的准确性，因此需要更高级的时间序列预测算法。
科学的时间序列预测起源于1930年代，目前有很多预测方法。传统的预测方法主要包括移动平均法法，分解法，指数平滑法，季节系数法，阈值自回归模型等。由于这些传统方法大多数都集中在理论研究上，因此很少有真正可以用来解决实际问题的方法。
随着观察时间窗口的扩大，历史时间序列数据逐渐变化，目标数据趋势越来越多样化和
复杂化。因此，有必要增加算法或模型的复杂度，以更好地拟合历史流量曲线，获得更好的
预测效果。近几十年来，出现了许多高级时间序列预测方法。例如，支持向量回归(Support
VectorRegression,SVR)，高斯过程(Gaussian Process,GP),神经网络(Neural Networks，NNs)等。？？论文提供了一种基于新型机器学习方法,即支持向量机(Support Vector Machine,简称为 SVM）的时间序列预测算法。当基础系统进程通常是非线性、非平稳且未定义先验条件时，SVM方法能够准确预测对应的时间序列，但也存在着算法运行速度过慢的问题。Zhu等人认为，改进的BP神经网络模型可以通过在交通流中输入多种特征来提高交通预测的准确性。但是，该方法通常收敛缓慢并且容易陷入局部最小值。随着深度学习算法的发展，一些深度神经网络因其出色的学习能力可以很好地预测非线性时间序列。但是，由于不同层和过滤器中的大量连接参数可能会花费大量的时间。此外，如果当前的算法结构不足以很好地拟合模型，则需要重新对所有输入数据进行训练过程。
2017-02-24，Facebook 发布了时间序列预测框架Prophet，与传统的时间序列预测方法相比，有以下优点:其具有较好的灵活性，轻松适应多个季节的季节性，并通过分析对趋势做出不同的假设;测量值不必呈等间距分布，也不需要插值缺失值;拟合速度较快;预测模型具有易于解释的参数，这些参数可通过分析对预测进行强加。虽然几十年来，国内外诸多学者在时间序列预测建模方面做了大量的工作，但现有的相关研究仍有一些有待改进的地方。

5.3 研究目标
课题希望达到的目标和特性如下：
（1）根据场景需求设计并开发出一个趋势预测算法模型，模型能够适用于运维平台进行监测的指标数据。
（2）运用趋势预测算法模型对实验数据进行仿真预测，调整算法参数，使其能够适用于真实场景并评估其准确性。
（3）基于智能运维平台软件系统算法框架，把趋势预测算法纳入指标异常检测的算法库中，丰富算法库，减少人工操作。
5.4 研究内容
5.4.1 主要内容
本文主要研究时间序列的分析预测方法，通过改进已有的模型和对模型进行融合来提高预测精度。并将提出的模型和方法应用于IT运维指标数据预测当中，具体研究内容如下：
（1）	提出基于STL分解和Prophet模型的趋势预测算法
本文对facebook提出的Prophet模型进行改进，使用STL分解的方法先分解时序数据，再运用Prophet模型对分解出的趋势成分做预测，最终形成基于STL分解和Prophet模型的趋势预测算法。
（2）	提出基于LSTM的趋势预测算法
为了应对复杂的实际时序数据，需要趋势预测算法能够适用于多种时间粒度的指标数据。基于LSTM的时序预测算法作为对上述算法的补充，让整个算法模型有更广的使用范围，更好地满足实际需求。
（3）	将算法模型应用于智能运维领域
智能运维平台系统提供实际的IT运维指标数据，算法需要对数据进行清洗、降噪等预处理，然后对处理后的指标数据进行预测，提供提供预测结果。软件系统判断预测值与当前监测值的差异，判断是否异常，把时序预测作为异常检测的一种重要手段。
5.4.2 文章结构
	本文组织结构如下：
第一章：绪论。对选题的背景和意义进行描述，通过各项事例和数据说明了时间序列预测的重要性以及智能运维领域运维指标预测的迫切性，并通过展开国内外研究现状调研，确立了问题的研究思路和解决方法。
第二章：相关理论概述。拟对智能运维、时间序列分析、趋势预测算法在AIOps中的作用等概念进行系统介绍，界定相关概念，并主要分析国内外学者在时间序列趋势预测方面的研究成果。
第三章：多粒度的时间序列趋势预测算法实现。从问题需求描述、算法模型设计、算法原理阐述等方面对趋势预测算法的实现过程进行重点分析。
第四章：实验设计与结果分析。通过设计实验以及对实验结果的分析，评估趋势预测算法的准确性、可靠性。包括实验环境、实验数据、评价指标和实验结果分析等几个方面。
第五章：总结与展望。总结整个课题研究过程，分析创新点和不足之处，并对后续的研究有所展望。 

5.5 主要研究方案、技术路线与可行性分析
  5.5.1 研究方案
本课题在广泛文献阅读、调研和分析国内外IT智能运维相关研究成果及公开的实践基础上，结合IT运维特点及IT运维实践中的各种关切问题，运用当前人工智能发展的最新研究成果，综合IT技术、通信技术、IT运维管理、可靠性管理、大数据技术、计算机科学、软件技术、人工智能技术等管理理论和应用技术，采用文献资料研究法、实验法、归纳法的等方法展开本课题研究、开发工作。
5.5.2 拟解决的主要问题
	综合上述文献调研可知，国内外许多学者都在对时间序列预测以及IT运维指标数据的预测进行积极的探索和研究，并且取得了一定的成果。例如，使用机器学习等方法对复杂的非线性的时间序列进行预测、采用神经网络模型对以小时、分钟为单位的细粒度的间序列进行预测等。但目前仍然存在一些问题，大致包括以下几点：
（1）	对时间序列趋势预测多是采用单一模型预测，未将多种预测模型融合使适用于线性、非线性等各种复杂的时间序列数据。
（2）	IT运维中对指标数据趋势预测算法的研究较少，许多优秀的时间序列预测算法模型还未应用于该领域，可对模型改进优化，使其在该领域上能有良好的表现。
（3）	大部分时序预测模型都是以月、季度、年等为单位，少有对以天或小时为单位的时间序列分析预测。
本论文在这些成果和问题的基础上，进行深入研究，拟解决以下主要问题：
（1）	单一算法模型难以适用复杂度很高的实际数据。融合多个算法模型，提高算法模型对实际数据复杂度高
（2）	优化改进已有趋势预测模型，应用于智能运维领域。
（3）	智能运维异常检测场景要求趋势预测结果有较高的精度、预测数据有较细的粒度，目前相关研究较少。
（4）	针对实际数据有缺失的情况，算法模型要有鲁棒性，有应对策略。

5.5.2 技术路线与可行性分析
 

5.6 预期研究成果和创新点
5.6.1 预期研究成果
	（1）设计并开发出基于天、月等时间单位的粗粒度时序数据趋势预测算法
	（2）设计并开发出基于
模型的主要优点如下:
1.支持多种时间粒度。同时支持以分钟、小时和天为粒度的时序数据。
2.运算速度快。相较于神经网络的方法计算速度更快。
3.准确度高。采用周期+趋势预测，预测结果精度高。
4.支持长时预测。预测结果不会随预测时间增长而趋势衰减

